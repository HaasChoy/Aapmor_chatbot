{"id": "55d6694e-cfbb-4d33-878a-ab2b6fec5cf2", "text": "sales. We can see that, on average, the chosen conﬁguration has better performance than both\nthe naive model (1,841.155) and the SARIMA model (1,551.842). This is impressive given that\nthe model operated on the raw data directly without scaling or the data being made stationary.\nNote: Given the stochastic nature of the algorithm, your speciﬁc results may vary. Consider\nrunning the example a few times.", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 277, "page_label": "261"}}