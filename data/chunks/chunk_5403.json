{"id": "d88b2d70-4a49-4ae1-9a19-ad7499a3d9b7", "text": "support for input sequences in RNNs oﬀers eﬃciency and greater performance for automatically\nlearning the temporal dependencies both within the input sequence and from the input sequence\nto the output.\n LSTM networks support eﬃcient learning of temporal dependencies.\nThese capabilities can also be combined, such as in the use of hybrid models like CNN-LSTMs\nand ConvLSTMs that seek to harness the capabilities of all three model types.", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 24, "page_label": "8"}}