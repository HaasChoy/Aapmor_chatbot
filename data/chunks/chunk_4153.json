{"id": "7a32eb28-b836-4f7b-a0fc-40617d99aaef", "text": "has a better condition number, but at the same time P−1 is easy to com-\npute. For further information on gradient descent, preconditioning, and\nconvergence we refer to Boyd and Vandenberghe (2004, chapter 9). ♦\n7.1.2 Gradient Descent With Momentum\nAs illustrated in Figure 7.3, the convergence of gradient descent may be\nvery slow if the curvature of the optimization surface is such that there\nare regions that are poorly scaled. The curvature is such that the gradient", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 235, "page_label": "230"}}