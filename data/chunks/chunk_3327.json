{"id": "525e9680-c933-4118-8db2-2c016974deaa", "text": "AA⊤= I= A⊤A, (3.29)\nwhich implies that\nA−1 = A⊤, (3.30)\ni.e., the inverse is obtained by simply transposing the matrix.It is convention to\ncall these matrices\n“orthogonal” but a\nmore precise\ndescription would\nbe “orthonormal”.\nTransformations by orthogonal matrices are special because the length\nof a vector xis not changed when transforming it using an orthogonal\nmatrix A. For the dot product, we obtain\nTransformations\nwith orthogonal\nmatrices preserve\ndistances and\nangles.\n∥Ax∥\n2", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 83, "page_label": "78"}}