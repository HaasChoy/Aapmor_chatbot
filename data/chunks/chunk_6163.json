{"id": "c426b374-6f3a-4dfc-a63e-43732201a1b6", "text": "Listing 9.89: Example of an Encoder-Decoder LSTM for multi-step forecasting for parallel series.\nRunning the example Ô¨Åts the model and predicts the values for each of the three time steps\nfor the next two time steps beyond the end of the dataset. We would expect the values for these\nseries and time steps to be as follows:\n90, 95, 185\n100, 105, 205\nListing 9.90: Expected output for an out-of-sample forecast.\nWe can see that the model forecast gets reasonably close to the expected values.", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 174, "page_label": "158"}}