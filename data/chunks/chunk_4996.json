{"id": "d98f6c32-18a8-41bc-a8c7-273d942173ff", "text": "12.1 Separating Hyperplanes\nGiven two examples represented as vectorsxi and xj, one way to compute\nthe similarity between them is using an inner product⟨xi,xj⟩. Recall from\nSection 3.2 that inner products are closely related to the angle between\ntwo vectors. The value of the inner product between two vectors depends\non the length (norm) of each vector. Furthermore, inner products allow\nus to rigorously deﬁne geometric concepts such as orthogonality and pro-\njections.", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 377, "page_label": "372"}}