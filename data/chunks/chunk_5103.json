{"id": "967cbe5a-eb5a-4958-9dcc-9bb2cd2820a9", "text": "terms in the explicit expansion grows very quickly (even for polynomials\nof low degree) when the input dimension is large. The kernel function\nonly requires one multiplication per input dimension, which can provide\nsigniﬁcant computational savings. Another example is the Gaussian ra-\ndial basis function kernel (Sch ¨olkopf and Smola, 2002; Rasmussen and\nWilliams, 2006), where the corresponding feature space is inﬁnite dimen-", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 395, "page_label": "390"}}