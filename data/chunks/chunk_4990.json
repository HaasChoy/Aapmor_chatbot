{"id": "e9094a89-2c2e-458a-9969-e6d5af264bcb", "text": "by designing a particular function that is to be optimized during training,\nbased on geometric intuitions. We have seen something similar already in\nChapter 10, where we derived PCA from geometric principles. In the SVM\ncase, we start by designing an objective function that is to be minimized\non training data, following the principles of empirical risk minimization\n(Section 8.2). This can also be understood as designing a particular loss\nfunction.", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 376, "page_label": "371"}}