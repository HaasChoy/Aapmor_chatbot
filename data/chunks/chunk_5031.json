{"id": "5e2dea09-d48b-440e-9348-d78a447ff9f6", "text": "378 Classiﬁcation with Support Vector Machines\n“hard” condition can be relaxed to accommodate violations if the data is\nnot linearly separable.\n12.2.3 Why We Can Set the Margin to 1\nIn Section 12.2.1, we argued that we would like to maximize some value\nr, which represents the distance of the closest example to the hyperplane.\nIn Section 12.2.2, we scaled the data such that the closest example is of\ndistance 1 to the hyperplane. In this section, we relate the two derivations,", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 383, "page_label": "378"}}