{"id": "05d6820c-21f8-4124-849a-7f6206b313d2", "text": "11.2 Parameter Learning via Maximum Likelihood 359\n=\nN∑\nn=1\nlog\nK∑\nk=1\nπkN\n(\nxn|µk, Σk\n)\n+ λ\n(K∑\nk=1\nπk −1\n)\n, (11.43b)\nwhere Lis the log-likelihood from (11.10) and the second term encodes\nfor the equality constraint that all the mixture weights need to sum up to\n1. We obtain the partial derivative with respect to πk as\n∂L\n∂πk\n=\nN∑\nn=1\nN\n(\nxn|µk, Σk\n)\n∑K\nj=1 πjN\n(\nxn|µj, Σj\n)+ λ (11.44a)\n= 1\nπk\nN∑\nn=1\nπkN\n(\nxn|µk, Σk\n)\n∑K\nj=1 πjN\n(\nxn|µj, Σj\n)\n  \n=Nk\n+λ= Nk\nπk\n+ λ, (11.44b)", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 364, "page_label": "359"}}