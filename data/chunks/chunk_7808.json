{"id": "bb8c7c47-5f74-4c75-903b-ff427bbbfd8b", "text": "chance of learning features from the input data. CNNs learn very quickly, so the dropout layer\nis intended to help slow down the learning process and hopefully result in a better ﬁnal model.\nThe pooling layer reduces the learned features to 1\n4 their size, consolidating them to only the\nmost essential elements. After the CNN and pooling, the learned features are ﬂattened to one\nlong vector and pass through a fully connected layer before the output layer used to make a", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 511, "page_label": "495"}}