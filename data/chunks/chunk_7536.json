{"id": "ac881061-4934-43fa-8e23-486e9b6b9abb", "text": "could be useful to cover diﬀerent sensor data time scales at deeper layers.\n— Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity\nRecognition, 2016.\nThe ﬁgure below taken from the paper makes the architecture clearer. Note that layers 6\nand 7 in the image are in fact LSTM layers.\nFigure 21.5: Depiction of CNN-LSTM Model for Activity Recognition. Taken from Deep Con-\nvolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition .", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 456, "page_label": "440"}}