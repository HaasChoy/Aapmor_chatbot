{"id": "af525386-4c32-4ee6-aaf3-2ff4b8ccb90a", "text": "Running the example Ô¨Årst prints the RMSE for each repeated evaluation of the model. At\nthe end of the run, we can see that indeed the model is skillful, achieving an average RMSE\nof 1,524.06, which is better than the naive model, the SARIMA model, and even the MLP\nmodel in the previous section. This is impressive given that the model operated on the raw data\ndirectly without scaling or the data being made stationary.", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 283, "page_label": "267"}}