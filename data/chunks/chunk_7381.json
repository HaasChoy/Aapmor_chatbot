{"id": "b6787ed9-1c8d-48b2-b3d4-9d56b776f826", "text": "forecasting.\nRunning the example ﬁts the model and summarizes the performance on the test dataset.\nWe can see that in this case, the model is skillful, achieving an overall RMSE score of about 372\nkilowatts.\nNote: Given the stochastic nature of the algorithm, your speciﬁc results may vary. Consider\nrunning the example a few times.\nlstm: [372.595] 379.5, 399.8, 339.6, 372.2, 370.9, 309.9, 424.8\nListing 20.21: Sample output from evaluating a univariate Encoder-Decoder LSTM model for", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 425, "page_label": "409"}}