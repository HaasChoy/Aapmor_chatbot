{"id": "dc325646-a594-485f-bd9b-9670ae601a41", "text": "7.1 Optimization Using Gradient Descent 229\nFigure 7.3 Gradient\ndescent on a\ntwo-dimensional\nquadratic surface\n(shown as a\nheatmap). See\nExample 7.1 for a\ndescription.\n−4 −2 0 2 4\nx1\n−2\n−1\n0\n1\n2\nx2\n0.0\n10.0\n20.0\n30.0\n40.0\n40.0\n50.0\n50.0\n60.070.0\n80.0\n−15\n0\n15\n30\n45\n60\n75\n90\nvalue (illustrated in Figure 7.3). We can see (both from the ﬁgure and\nby plugging x0 into (7.8)) that the gradient at x0 points north and\neast, leading to x1 = [ −1.98,1.21]⊤. Repeating that argument gives us", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 234, "page_label": "229"}}