{"id": "b92fb941-f1ba-4e8b-a620-63120d77105e", "text": "LSTM layer is followed by a fully connected layer with 200 nodes that will interpret the features\nlearned by the LSTM layer. Finally, an output layer will directly predict a vector with seven\nelements, one for each day in the output sequence. We will use the mean squared error loss\nfunction as it is a good match for our chosen error metric of RMSE. We will use the eﬃcient\nAdam implementation of stochastic gradient descent and ﬁt the model for 70 epochs with a\nbatch size of 16.", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 414, "page_label": "398"}}