{"id": "3e790781-e9a2-4140-a7b9-cbd9421bc296", "text": "served function values y∈R, which we can interpret as the labels of their\nrespective inputs. We will discuss classical model ﬁtting (parameter esti-\nmation) via maximum likelihood and maximum a posteriori estimation,\nas well as Bayesian linear regression, where we integrate the parameters\nout instead of optimizing them.\nChapter 10 focuses on dimensionality reduction, the second pillar in Fig- dimensionality\nreductionure 1.1, using principal component analysis. The key objective of dimen-", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 20, "page_label": "15"}}