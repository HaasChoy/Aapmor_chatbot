{"id": "529a6c20-47b2-48ac-9429-b2d9f6d95549", "text": "use symmetrized matrices: Symmetry requires S = S⊤, and by insert-\ning (4.36) we obtain S = A⊤A= A⊤(A⊤)⊤ = (A⊤A)⊤ = S⊤. More-\nover, positive semideﬁniteness (Section 3.2.3) requires that x⊤Sx ⩾0\nand inserting (4.36) we obtain x⊤Sx = x⊤A⊤Ax = (x⊤A⊤)(Ax) =\n(Ax)⊤(Ax) ⩾ 0, because the dot product computes a sum of squares\n(which are themselves non-negative).\nspectral theorem\nTheorem 4.15 (Spectral Theorem). If A ∈Rn×n is symmetric, there ex-", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 116, "page_label": "111"}}