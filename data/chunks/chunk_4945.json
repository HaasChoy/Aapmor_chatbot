{"id": "12f5200d-3b4d-47cc-98b6-ec548031b47a", "text": "ities, and (iii) the iterative algorithm for updating the model parameters\ncan be derived in a principled manner as the EM algorithm for maximum\nlikelihood parameter estimation in latent-variable models.\n11.4.1 Generative Process and Probabilistic Model\nTo derive the probabilistic model for GMMs, it is useful to think about the\ngenerative process, i.e., the process that allows us to generate data, using\na probabilistic model.\nWe assume a mixture model with K components and that a data point", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 368, "page_label": "363"}}