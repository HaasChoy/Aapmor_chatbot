{"id": "e8d0882e-dc0c-48ae-9086-a08723cde5f9", "text": "We can use the same output layer or layers to make each one-step prediction in the output\nsequence. This can be achieved by wrapping the output part of the model in a TimeDistributed\nwrapper.\n# define model output\nmodel.add(TimeDistributed(Dense(1)))\nListing 9.69: Example of deﬁning the output model.\nThe full deﬁnition for an Encoder-Decoder model for multi-step time series forecasting is\nlisted below.\n# define model\nmodel = Sequential()", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 165, "page_label": "149"}}