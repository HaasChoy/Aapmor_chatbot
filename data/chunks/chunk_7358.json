{"id": "222a7f31-e510-49ca-9601-daa1f0c3d8a5", "text": "decoder will output the entire sequence, not just the output at the end of the sequence as we\ndid with the encoder. This means that each of the 200 units will output a value for each of the\nseven days, representing the basis for what to predict for each day in the output sequence.\n# define decoder model\nmodel.add(LSTM(200, activation=' relu' , return_sequences=True))\nListing 20.16: Example of deÔ¨Åning the decoder model.", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 421, "page_label": "405"}}