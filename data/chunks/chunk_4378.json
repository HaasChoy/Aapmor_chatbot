{"id": "d5a3c725-2514-4ecf-91a9-5c67c05b6931", "text": ")\n, where Î£ is the covari-\nance matrix (Section 6.5). Note that the conjugate prior of a Gaussian\nis also a Gaussian (Section 6.6.1), and therefore we expect the posterior\ndistribution to also be a Gaussian. We will see the details of maximum a\nposteriori estimation in Chapter 9.\nThe idea of including prior knowledge about where good parameters\nlie is widespread in machine learning. An alternative view, which we saw\nin Section 8.2.3, is the idea of regularization, which introduces an addi-", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 274, "page_label": "269"}}