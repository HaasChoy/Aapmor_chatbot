{"id": "e7b06bc1-defa-4ace-9a26-7a3bbcd156a0", "text": "382 Classiﬁcation with Support Vector Machines\nFigure 12.8 The\nhinge loss is a\nconvex upper bound\nof zero-one loss.\n−2 0 2\nt\n0\n2\n4max{0, 1 − t} Zero-one loss\nHinge loss\nThis loss can be interpreted as never allowing any examples inside the\nmargin.\nFor a given training set {(x1,y1),..., (xN,yN)}, we seek to minimize\nthe total loss, while regularizing the objective with ℓ2-regularization (see\nSection 8.2.3). Using the hinge loss (12.28) gives us the unconstrained\noptimization problem\nmin\nw,b\n1", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 387, "page_label": "382"}}