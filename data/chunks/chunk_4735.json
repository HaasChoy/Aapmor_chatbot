{"id": "498c1cec-b8ae-48e5-8533-d4b2dc0f2e6b", "text": "Instead of these absolute quantities, we can deﬁne the relative variance\ncaptured as VM\nVD\n, and the relative variance lost by compression as 1 −VM\nVD\n.\n10.3 Projection Perspective\nIn the following, we will derive PCA as an algorithm that directly mini-\nmizes the average reconstruction error. This perspective allows us to in-\nterpret PCA as implementing an optimal linear auto-encoder. We will draw\nheavily from Chapters 2 and 3.\nIn the previous section, we derived PCA by maximizing the variance", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 330, "page_label": "325"}}