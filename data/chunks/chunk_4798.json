{"id": "f72d446f-4fb4-49ea-bef2-0f6e848e134f", "text": "free, and it has variance 1 along each axis, which is indicated by the\ntwo arrows in Figure 10.10(c). This step completes thestandardizationstandardization\nof the data.\n3. Eigendecomposition of the covariance matrix Compute the data\ncovariance matrix and its eigenvalues and corresponding eigenvectors.\nSince the covariance matrix is symmetric, the spectral theorem (The-\norem 4.15) states that we can Ô¨Ånd an ONB of eigenvectors. In Fig-", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 341, "page_label": "336"}}