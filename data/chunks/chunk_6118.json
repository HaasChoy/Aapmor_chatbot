{"id": "4043ffab-d302-475b-8c9a-d311c032d07b", "text": "listed below.\n# define model\nmodel = Sequential()\nmodel.add(LSTM(100, activation=' relu' , input_shape=(n_steps_in, n_features)))\nmodel.add(RepeatVector(n_steps_out))\nmodel.add(LSTM(100, activation=' relu' , return_sequences=True))\nmodel.add(TimeDistributed(Dense(1)))\nmodel.compile(optimizer=' adam' , loss=' mse' )\nListing 9.70: Example of deÔ¨Åning an Encoder-Decoder LSTM for multi-step forecasting.\nAs with other LSTM models, the input data must be reshaped into the expected three-", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 165, "page_label": "149"}}