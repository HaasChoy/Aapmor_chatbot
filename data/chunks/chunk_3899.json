{"id": "2a775575-72a9-4ec7-9ef3-753e59545d19", "text": "x, and it ensures that the posterior p(x|y) is normalized. The marginal\nlikelihood can also be interpreted as the expected likelihood where we\ntake the expectation with respect to the prior p(x). Beyond normalization\nof the posterior, the marginal likelihood also plays an important role in\nBayesian model selection, as we will discuss in Section 8.6. Due to the\nintegration in (8.44), the evidence is often hard to compute.Bayes’ theorem is\nalso called the\n“probabilistic\ninverse.”", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 191, "page_label": "186"}}