{"id": "eb8c0eaf-6a91-4a29-8a22-20fb58ccf5b4", "text": "least in this simpliﬁed framing. We can also see the drop of SVM to about 72% accuracy. The\ngood performance of ensembles of decision trees may suggest the need for feature selection and\nthe ensemble methods ability to select those features that are most relevant to predicting the\nassociated activity.\nNote: Given the stochastic nature of the algorithm, your speciﬁc results may vary. Consider\nrunning the example a few times.\nDefined 8 models\n>knn: 61.893\n>cart: 72.141\n>svm: 76.960\n>bayes: 72.480", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 504, "page_label": "488"}}