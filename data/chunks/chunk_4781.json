{"id": "f2b3198c-3405-494f-b06f-a20a39b14653", "text": "trix Bin (10.3), which projects the original data onto a lower-dimensional\nsubspace of dimension M. The Eckart-Young theorem (Theorem 4.25 inEckart-Young\ntheorem Section 4.6) offers a direct way to estimate the low-dimensional represen-\ntation. Consider the best rank-M approximation\n˜XM := argminrk(A)⩽M ∥X−A∥2 ∈RD×N (10.50)\nof X, where ∥·∥2 is the spectral norm deﬁned in (4.93). The Eckart-Young\ntheorem states that ˜XM is given by truncating the SVD at the top- M", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 339, "page_label": "334"}}