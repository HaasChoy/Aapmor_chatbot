{"id": "a46f05e7-a59f-4de1-a1f1-77d9e3514ce5", "text": "features from a subsequence of raw sample data, and output features from the CNN for each\nsubsequence are then interpreted by an LSTM in aggregate. An example of this is in the 2016\npaper by Francisco Javier Ordonez and Daniel Roggen titled Deep Convolutional and LSTM\nRecurrent Neural Networks for Multimodal Wearable Activity Recognition.\nWe introduce a new DNN framework for wearable activity recognition, which we\nrefer to as DeepConvLSTM. This architecture combines convolutional and recurrent", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 455, "page_label": "439"}}