{"id": "ab166b06-8282-424d-bad1-f29c7b821773", "text": "min\nw,b\n1\n2 ∥w∥\n2\n  \nmargin\nsubject to yn(⟨w,xn⟩+ b) ⩾1  \ndata ﬁtting\n.\n(12.21)\nProof Consider (12.20). Since the square is a strictly monotonic trans-\nformation for non-negative arguments, the maximum stays the same if we\nconsider r2 in the objective. Since ∥w∥= 1 we can reparametrize the\nequation with a new weight vector w′that is not normalized by explicitly\nusing w′\n∥w′∥. We obtain\nmax\nw′,b,r\nr2\nsubject to yn\n(⟨ w′\n∥w′∥,xn\n⟩\n+ b\n)\n⩾r, r> 0 .\n(12.22)", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 383, "page_label": "378"}}