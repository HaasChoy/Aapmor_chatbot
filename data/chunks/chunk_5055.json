{"id": "ff646071-da57-4ed7-ade0-f1ff6feca860", "text": "optimization problem\nmin\nw,b\n1\n2∥w∥2\n  \nregularizer\n+ C\nN∑\nn=1\nmax{0,1 −yn(⟨w,xn⟩+ b)}\n  \nerror term\n. (12.31)\nThe ﬁrst term in (12.31) is called the regularization term or theregularizerregularizer\n(see Section 9.2.3), and the second term is called theloss term or the errorloss term\nerror term term. Recall from Section 12.2.4 that the term 1\n2 ∥w∥\n2\narises directly from\nthe margin. In other words, margin maximization can be interpreted as\nregularization.regularization", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 387, "page_label": "382"}}