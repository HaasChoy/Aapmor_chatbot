{"id": "749075d9-c319-407b-accb-0bb2e4f514a2", "text": "21.6. Recurrent Neural Network Models 438\nactivity recognition. The LSTM learns to map each window of sensor data to an activity, where\nthe observations in the input sequence are read one at a time, where each time step may be\ncomprised of one or more variables (e.g. parallel sequences).\nThere has been limited application of simple LSTM models to HAR problems. One example\nis by Abdulmajid Murad and Jae-Young Pyun in their 2017 paper titled Deep Recurrent Neural", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 454, "page_label": "438"}}