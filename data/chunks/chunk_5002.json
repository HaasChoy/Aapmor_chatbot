{"id": "0346563f-5094-42ee-9369-6185da398d65", "text": "(Section 3.2). Since we have chosen xa and xb to be on the hyperplane,\nthis implies that f(xa) = 0 and f(xb) = 0 and hence ⟨w,xa −xb⟩= 0.\nRecall that two vectors are orthogonal when their inner product is zero. wis orthogonal to\nany vector on the\nhyperplane.\nTherefore, we obtain thatwis orthogonal to any vector on the hyperplane.\nRemark. Recall from Chapter 2 that we can think of vectors in different\nways. In this chapter, we think of the parameter vector w as an arrow", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 378, "page_label": "373"}}