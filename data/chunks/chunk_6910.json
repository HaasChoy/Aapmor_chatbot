{"id": "8a67bbaa-e693-4e36-a9bb-3bdb422518c8", "text": "The LSTM model is quite a bit slower to train than MLP and CNN models; as such, you\nmay want to evaluate fewer conﬁgurations per run. We will deﬁne a very simple set of two\nconﬁgurations to explore: stochastic and batch gradient descent.\n# create a list of configs to try\ndef model_configs():\n# define scope of configs\nn_input = [12]\nn_nodes = [100]\nn_epochs = [50]\nn_batch = [1, 150]\nn_diff = [12]\n# create configs\nconfigs = list()\nfor i in n_input:\nfor j in n_nodes:\nfor k in n_epochs:", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 330, "page_label": "314"}}