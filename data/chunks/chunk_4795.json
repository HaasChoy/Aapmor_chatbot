{"id": "66bb40fb-0e17-41f6-b809-209d7f0c3bd4", "text": "we know the eigenvectors of 1\nNX⊤X. If we left-multiply our eigenvalue/\neigenvector equation with X, we get\n1\nNXX⊤\n  \nS\nXcm = λmXcm (10.57)\nand we recover the data covariance matrix again. This now also means\nthat we recover Xcm as an eigenvector of S.\nRemark. If we want to apply the PCA algorithm that we discussed in Sec-\ntion 10.6, we need to normalize the eigenvectors Xcm of Sso that they\nhave norm 1. ♦\n10.6 Key Steps of PCA in Practice", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 341, "page_label": "336"}}