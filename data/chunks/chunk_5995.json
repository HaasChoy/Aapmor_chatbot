{"id": "7c71982a-6744-4cd1-9347-a9a7110fac04", "text": "# reshape from [samples, timesteps] into [samples, timesteps, features]\nn_features = 1\nX = X.reshape((X.shape[0], X.shape[1], n_features))\nListing 9.7: Example of reshaping training data for the LSTM.\nIn this case, we deﬁne a model with 50 LSTM units in the hidden layer and an output layer\nthat predicts a single numerical value. The model is ﬁt using the eﬃcient Adam version of\nstochastic gradient descent and optimized using the mean squared error, or ‘mse’ loss function.", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 142, "page_label": "126"}}