{"id": "2a175fd9-8e73-46ae-a625-42a6c9934c7e", "text": "dollars or weight. The contrived example above is a regression problem.\n4.2 Sliding Window\nTime series data can be phrased as supervised learning. Given a sequence of numbers for a time\nseries dataset, we can restructure the data to look like a supervised learning problem. We can\ndo this by using previous time steps as input variables and use the next time step as the output\nvariable. Letâ€™s make this concrete with an example. Imagine we have a time series as follows:\ntime, measure\n1, 100\n2, 110", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 41, "page_label": "25"}}