{"id": "448d6d13-7263-4427-9891-173e3398d568", "text": "chine learning are intended to be minimized, that is, the best value is the\nminimum value. Intuitively ﬁnding the best value is like ﬁnding the val-\nleys of the objective function, and the gradients point us uphill. The idea is\nto move downhill (opposite to the gradient) and hope to ﬁnd the deepest\npoint. For unconstrained optimization, this is the only concept we need,\nbut there are several design choices, which we discuss in Section 7.1. For", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 230, "page_label": "225"}}