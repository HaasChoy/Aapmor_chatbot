{"id": "b1f69660-f06d-4215-9b71-79146b1b6764", "text": "202 Probability and Distributions\nRemark. A case that will be useful in Chapter 11 is the weighted sum of\nGaussian densities. This is different from the weighted sum of Gaussian\nrandom variables. ♦\nIn Theorem 6.12, the random variable x is from a density that is a\nmixture of two densitiesp1(x) and p2(x), weighted by α. The theorem can\nbe generalized to the multivariate random variable case, since linearity of\nexpectations holds also for multivariate random variables. However, the", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 207, "page_label": "202"}}