{"id": "fd549672-1784-4c95-8273-03b45eedbe82", "text": "170 Vector Calculus\n5.9 Further Reading\nFurther details of matrix differentials, along with a short review of the\nrequired linear algebra, can be found in Magnus and Neudecker (2007).\nAutomatic differentiation has had a long history , and we refer to Griewank\nand Walther (2003), Griewank and Walther (2008), and Elliott (2009)\nand the references therein.\nIn machine learning (and other disciplines), we often need to compute\nexpectations, i.e., we need to solve integrals of the form\nEx[f(x)] =\nâˆ«", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 175, "page_label": "170"}}