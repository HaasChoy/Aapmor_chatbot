{"id": "dfd45392-9d64-4199-9197-6c19b01bc181", "text": "162 Vector Calculus\nIn the following, we will focus on reverse mode automatic differentia-\ntion, which is backpropagation. In the context of neural networks, where\nthe input dimensionality is often much higher than the dimensionality of\nthe labels, the reverse mode is computationally signiﬁcantly cheaper than\nthe forward mode. Let us start with an instructive example.\nExample 5.14\nConsider the function\nf(x) =\n√\nx2 + exp(x2) + cos\n(\nx2 + exp(x2)\n)\n(5.122)", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 167, "page_label": "162"}}