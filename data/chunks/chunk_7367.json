{"id": "a1c61d74-fc99-4eb3-92e6-f87db1f663c6", "text": "model.add(TimeDistributed(Dense(1)))\nmodel.compile(loss=' mse' , optimizer=' adam' )\n# fit network\nmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\nreturn model\nListing 20.19: Example of a function for deﬁning and ﬁtting an encoder-decoder LSTM model.\nThe complete example with the encoder-decoder model is listed below.\n# univariate multi-step encoder-decoder lstm for the power usage dataset\nfrom math import sqrt\nfrom numpy import split\nfrom numpy import array", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 422, "page_label": "406"}}