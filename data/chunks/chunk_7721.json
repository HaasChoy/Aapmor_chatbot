{"id": "2b31c0d0-81ef-4bbe-9f5b-b2d6d364f951", "text": "23.3. Modeling Feature Engineered Data 480\nNonlinear Algorithms:\n k-Nearest Neighbors\n Classiﬁcation and Regression Tree\n Support Vector Machine\n Naive Bayes\nEnsemble Algorithms:\n Bagged Decision Trees\n Random Forest\n Extra Trees\n Gradient Boosting Machine\nWe will deﬁne the models and store them in a dictionary that maps the model object to a\nshort name that will help in analyzing the results. The define models() function below deﬁnes\nthe eight models that we will evaluate.", "metadata": {"producer": "pdfTeX-1.40.18", "creator": "LaTeX with hyperref package", "creationdate": "2018-11-01T07:53:25+11:00", "author": "", "title": "", "subject": "", "keywords": "", "moddate": "2018-11-01T07:53:25+11:00", "trapped": "/False", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Deep Learning for Time Series Forecasting - Predict the Future with MLPs, CNNs and LSTMs in Python (Jason Brownlee) (Z-Library).pdf", "total_pages": 574, "page": 496, "page_label": "480"}}