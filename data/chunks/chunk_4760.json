{"id": "62a1902b-46ab-4eee-a788-c3a256260d94", "text": "330 Dimensionality Reduction with Principal Component Analysis\nFigure 10.9\nOrthogonal\nprojection and\ndisplacement\nvectors. When\nprojecting data\npoints xn (blue)\nonto subspace U1,\nwe obtain ˜xn\n(orange). The\ndisplacement vector\n˜xn−xn lies\ncompletely in the\northogonal\ncomplement U2 of\nU1.\n−5 0 5\nx1\n−6\n−4\n−2\n0\n2\n4\n6\nx2\nU\nU⊥\nSince we can generally write the original data point xn as a linear combi-\nnation of all basis vectors, it holds that\nxn =\nD∑\nd=1\nzdnbd\n(10.32)\n=\nD∑\nd=1\n(x⊤\nnbd)bd =\n( D∑\nd=1", "metadata": {"producer": "pdfTeX-1.40.20", "creator": "LaTeX with hyperref", "creationdate": "2019-10-15T12:48:02+01:00", "author": "Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong", "keywords": "", "moddate": "2020-01-03T10:00:34+02:00", "ptex.fullbanner": "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019) kpathsea version 6.3.1", "subject": "", "title": "Mathematics for Machine Learning", "trapped": "/False", "source": "/home/haas/rag_proj/samples/AAPMOR Website/Mathematics for Machine Learning ( etc.) (Z-Library).pdf", "total_pages": 417, "page": 335, "page_label": "330"}}